{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n               .appName('SparkByExamples.com') \\\n               .getOrCreate()\n\nfrom pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c82a5683-f5a3-4eb3-be24-3efa9593d0a1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df=spark.createDataFrame([[\"1\"]],[\"id\"])\ndf.select(current_date().alias(\"current_date\"), \\\n      date_format(current_date(),\"yyyy MM dd\").alias(\"yyyy MM dd\"), \\\n      date_format(current_timestamp(),\"MM/dd/yyyy hh:mm\").alias(\"MM/dd/yyyy\"), \\\n      date_format(current_timestamp(),\"yyyy MMM dd\").alias(\"yyyy MMMM dd\"), \\\n      date_format(current_timestamp(),\"yyyy MMMM dd E\").alias(\"yyyy MMMM dd E\") \\\n   ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f66a0880-aed1-49d8-842e-37fb648151d9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------------+----------+----------------+------------+----------------+\n|current_date|yyyy MM dd|      MM/dd/yyyy|yyyy MMMM dd|  yyyy MMMM dd E|\n+------------+----------+----------------+------------+----------------+\n|  2023-06-14|2023 06 14|06/14/2023 01:38| 2023 Jun 14|2023 June 14 Wed|\n+------------+----------+----------------+------------+----------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#SQL\n\nspark.sql(\"select current_date() as current_date, date_format(current_timestamp(),'yyyy MM dd') as yyyy_MM_dd, \"+\n      \"date_format(current_timestamp(),'MM/dd/yyyy hh:mm') as MM_dd_yyyy, \"+\n      \"date_format(current_timestamp(),'yyyy MMM dd') as yyyy_MMMM_dd, \"+\n      \"date_format(current_timestamp(),'yyyy MMMM dd E') as yyyy_MMMM_dd_E\").show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4c5d0d28-52aa-4c39-bba4-51a580cd560b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------------+----------+----------------+------------+----------------+\n|current_date|yyyy_MM_dd|      MM_dd_yyyy|yyyy_MMMM_dd|  yyyy_MMMM_dd_E|\n+------------+----------+----------------+------------+----------------+\n|  2023-06-14|2023 06 14|06/14/2023 01:47| 2023 Jun 14|2023 June 14 Wed|\n+------------+----------+----------------+------------+----------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n# Create SparkSession\nspark = SparkSession.builder \\\n               .appName('SparkByExamples.com') \\\n               .getOrCreate()\ndata=[[\"1\",\"2020-02-01\"],[\"2\",\"2019-03-01\"],[\"3\",\"2021-03-01\"]]\ndf=spark.createDataFrame(data,[\"id\",\"input\"])\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"64fc814b-7b90-4e4e-a6bc-9f692a6e8ebc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+----------+\n| id|     input|\n+---+----------+\n|  1|2020-02-01|\n|  2|2019-03-01|\n|  3|2021-03-01|\n+---+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *\n\n#current_date()\ndf.select(current_date().alias(\"current_date\")\n  ).show(1)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7bb923d0-e742-49c4-88f8-6d97ce67335d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+------------+\n|current_date|\n+------------+\n|  2023-06-14|\n+------------+\nonly showing top 1 row\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.columns\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"acfea751-c709-45f3-a445-c7199559cfd2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[8]: ['id', 'input']"]}],"execution_count":0},{"cell_type":"code","source":["df.select(col(\"input\"), \n    date_format(col(\"input\"), \"MM-dd-yyyy\").alias(\"date_format\") \n  ).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1998ae94-a83c-4c23-bc89-48fa971e8fef","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+-----------+\n|     input|date_format|\n+----------+-----------+\n|2020-02-01| 02-01-2020|\n|2019-03-01| 03-01-2019|\n|2021-03-01| 03-01-2021|\n+----------+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#to_date()\ndf.select(col(\"input\"), \n    to_date(col(\"input\"), \"yyy-MM-dd\").alias(\"to_date\") \n  ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4a3d2aa9-9908-4e4e-ac62-47a77f206bc9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+----------+\n|     input|   to_date|\n+----------+----------+\n|2020-02-01|2020-02-01|\n|2019-03-01|2019-03-01|\n|2021-03-01|2021-03-01|\n+----------+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\n#months_between()\ndf.select(col(\"input\"), \n    months_between(current_date(),col(\"input\")).alias(\"months_between\")  \n  ).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"fa88146a-81f5-4d23-8db0-74f553e582be","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+--------------+\n|     input|months_between|\n+----------+--------------+\n|2020-02-01|   40.41935484|\n|2019-03-01|   51.41935484|\n|2021-03-01|   27.41935484|\n+----------+--------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#months_between()\ndf.select(col(\"input\"), \n    datediff(month,current_date(),col(\"input\")).alias(\"months_between\")  \n  ).show()\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"06d4b5e2-9f99-4fc8-ab87-3e0b38945040","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-3181585569916271>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#months_between()\u001B[39;00m\n\u001B[1;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39mselect(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m), \n\u001B[0;32m----> 3\u001B[0m     \u001B[43mdatediff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonth\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcurrent_date\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmonths_between\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \n\u001B[1;32m      4\u001B[0m   )\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py:164\u001B[0m, in \u001B[0;36mtry_remote_functions.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(functions, f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\n\u001B[0;31mTypeError\u001B[0m: datediff() takes 2 positional arguments but 3 were given","errorSummary":"<span class='ansi-red-fg'>TypeError</span>: datediff() takes 2 positional arguments but 3 were given","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n","\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n","File \u001B[0;32m<command-3181585569916271>:3\u001B[0m\n","\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#months_between()\u001B[39;00m\n","\u001B[1;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39mselect(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m\"\u001B[39m), \n","\u001B[0;32m----> 3\u001B[0m     \u001B[43mdatediff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonth\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcurrent_date\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmonths_between\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \n","\u001B[1;32m      4\u001B[0m   )\u001B[38;5;241m.\u001B[39mshow()\n","\n","File \u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py:164\u001B[0m, in \u001B[0;36mtry_remote_functions.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n","\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(functions, f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n","\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n","\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n","\n","\u001B[0;31mTypeError\u001B[0m: datediff() takes 2 positional arguments but 3 were given"]}}],"execution_count":0},{"cell_type":"code","source":["#trunc()\ndf.select(col(\"input\"), \n    trunc(col(\"input\"),\"Month\").alias(\"Month_Trunc\"), \n    trunc(col(\"input\"),\"Year\").alias(\"Month_Year\"), \n    trunc(col(\"input\"),\"Month\").alias(\"Month_Trunc\")\n   ).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1f862df0-c861-411e-bedf-1fa6e0930c52","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+-----------+----------+-----------+\n|     input|Month_Trunc|Month_Year|Month_Trunc|\n+----------+-----------+----------+-----------+\n|2020-02-01| 2020-02-01|2020-01-01| 2020-02-01|\n|2019-03-01| 2019-03-01|2019-01-01| 2019-03-01|\n|2021-03-01| 2021-03-01|2021-01-01| 2021-03-01|\n+----------+-----------+----------+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#trunc()\ndf.select(current_date(), \n    trunc(current_date(),\"Month\").alias(\"Month_Trunc\"), \n    trunc(current_date(),\"Year\").alias(\"Month_Year\"), \n    trunc(current_date(),\"Month\").alias(\"Month_Trunc\")\n   ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"535a556a-f8a5-4ff9-aa09-cd6ba98a31fc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------------+-----------+----------+-----------+\n|current_date()|Month_Trunc|Month_Year|Month_Trunc|\n+--------------+-----------+----------+-----------+\n|    2023-06-14| 2023-06-01|2023-01-01| 2023-06-01|\n|    2023-06-14| 2023-06-01|2023-01-01| 2023-06-01|\n|    2023-06-14| 2023-06-01|2023-01-01| 2023-06-01|\n+--------------+-----------+----------+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#add_months() , date_add(), date_sub()\n\ndf.select(col(\"input\"), \n    add_months(col(\"input\"),3).alias(\"add_months\"), \n    add_months(col(\"input\"),-3).alias(\"sub_months\"), \n    date_add(col(\"input\"),4).alias(\"date_add\"), \n    date_sub(col(\"input\"),4).alias(\"date_sub\") \n  ).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c2f5929c-ad26-4c75-aeab-75a37a82117e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+----------+----------+----------+----------+\n|     input|add_months|sub_months|  date_add|  date_sub|\n+----------+----------+----------+----------+----------+\n|2020-02-01|2020-05-01|2019-11-01|2020-02-05|2020-01-28|\n|2019-03-01|2019-06-01|2018-12-01|2019-03-05|2019-02-25|\n|2021-03-01|2021-06-01|2020-12-01|2021-03-05|2021-02-25|\n+----------+----------+----------+----------+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(col(\"input\"), \n     year(col(\"input\")).alias(\"year\"), \n     month(col(\"input\")).alias(\"month\"), \n     next_day(col(\"input\"),\"Sunday\").alias(\"next_day\"), \n     weekofyear(col(\"input\")).alias(\"weekofyear\") \n  ).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4c036047-eb9d-4ccf-9aaf-8788ce1e0d47","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+----+-----+----------+----------+\n|     input|year|month|  next_day|weekofyear|\n+----------+----+-----+----------+----------+\n|2020-02-01|2020|    2|2020-02-02|         5|\n|2019-03-01|2019|    3|2019-03-03|         9|\n|2021-03-01|2021|    3|2021-03-07|         9|\n+----------+----+-----+----------+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\ndf.select(col(\"input\"),  \n     dayofweek(col(\"input\")).alias(\"dayofweek\"), \n     dayofmonth(col(\"input\")).alias(\"dayofmonth\"), \n     dayofyear(col(\"input\")).alias(\"dayofyear\"), \n  ).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4eb91748-f7c1-4169-9b28-6097c898c018","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+---------+----------+---------+\n|     input|dayofweek|dayofmonth|dayofyear|\n+----------+---------+----------+---------+\n|2020-02-01|        7|         1|       32|\n|2019-03-01|        6|         1|       60|\n|2021-03-01|        2|         1|       60|\n+----------+---------+----------+---------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["data=[[\"1\",\"02-01-2020 11 01 19 06\"],[\"2\",\"03-01-2019 12 01 19 406\"],[\"3\",\"03-01-2021 12 01 19 406\"]]\ndf2=spark.createDataFrame(data,[\"id\",\"input\"])\ndf2.show(truncate=False)\n\n#current_timestamp()\ndf2.select(current_timestamp().alias(\"current_timestamp\")\n  ).show(1,truncate=False)\n\n#to_timestamp()\ndf2.select(col(\"input\"), \n    to_timestamp(col(\"input\"), \"MM-dd-yyyy HH mm ss SSS\").alias(\"to_timestamp\") \n  ).show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f5c22db2-5a8f-4889-8281-0b5f1c1d5c0a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+-----------------------+\n|id |input                  |\n+---+-----------------------+\n|1  |02-01-2020 11 01 19 06 |\n|2  |03-01-2019 12 01 19 406|\n|3  |03-01-2021 12 01 19 406|\n+---+-----------------------+\n\n+-----------------------+\n|current_timestamp      |\n+-----------------------+\n|2023-06-14 04:27:48.677|\n+-----------------------+\nonly showing top 1 row\n\n+-----------------------+-----------------------+\n|input                  |to_timestamp           |\n+-----------------------+-----------------------+\n|02-01-2020 11 01 19 06 |2020-02-01 11:01:19.06 |\n|03-01-2019 12 01 19 406|2019-03-01 12:01:19.406|\n|03-01-2021 12 01 19 406|2021-03-01 12:01:19.406|\n+-----------------------+-----------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\n#hour, minute,second\ndata=[[\"1\",\"2020-02-01 11:01:19.06\"],[\"2\",\"2019-03-01 12:01:19.406\"],[\"3\",\"2021-03-01 12:01:19.406\"]]\ndf3=spark.createDataFrame(data,[\"id\",\"input\"])\n\ndf3.select(col(\"input\"), \n    hour(col(\"input\")).alias(\"hour\"), \n    minute(col(\"input\")).alias(\"minute\"),\n    second(col(\"input\")).alias(\"second\") \n  ).show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"81ab23a8-8427-4780-b8f3-32393d1b3004","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-----------------------+----+------+------+\n|input                  |hour|minute|second|\n+-----------------------+----+------+------+\n|2020-02-01 11:01:19.06 |11  |1     |19    |\n|2019-03-01 12:01:19.406|12  |1     |19    |\n|2021-03-01 12:01:19.406|12  |1     |19    |\n+-----------------------+----+------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n# Create SparkSession\nspark = SparkSession.builder \\\n               .appName('SparkByExamples.com') \\\n               .getOrCreate()\ndata=[[\"1\",\"2020-02-01\"],[\"2\",\"2019-03-01\"],[\"3\",\"2021-03-01\"]]\ndf=spark.createDataFrame(data,[\"id\",\"input\"])\ndf.show()\n\nfrom pyspark.sql.functions import *\n\n#current_date()\ndf.select(current_date().alias(\"current_date\")\n  ).show(1)\n\n#date_format()\ndf.select(col(\"input\"), \n    date_format(col(\"input\"), \"MM-dd-yyyy\").alias(\"date_format\") \n  ).show()\n\n#to_date()\ndf.select(col(\"input\"), \n    to_date(col(\"input\"), \"yyy-MM-dd\").alias(\"to_date\") \n  ).show()\n\n#datediff()\ndf.select(col(\"input\"), \n    datediff(current_date(),col(\"input\")).alias(\"datediff\")  \n  ).show()\n\n#months_between()\ndf.select(col(\"input\"), \n    months_between(current_date(),col(\"input\")).alias(\"months_between\")  \n  ).show()\n\n#trunc()\ndf.select(col(\"input\"), \n    trunc(col(\"input\"),\"Month\").alias(\"Month_Trunc\"), \n    trunc(col(\"input\"),\"Year\").alias(\"Month_Year\"), \n    trunc(col(\"input\"),\"Month\").alias(\"Month_Trunc\")\n   ).show()\n\n#add_months() , date_add(), date_sub()\n\ndf.select(col(\"input\"), \n    add_months(col(\"input\"),3).alias(\"add_months\"), \n    add_months(col(\"input\"),-3).alias(\"sub_months\"), \n    date_add(col(\"input\"),4).alias(\"date_add\"), \n    date_sub(col(\"input\"),4).alias(\"date_sub\") \n  ).show()\n\n#\n\ndf.select(col(\"input\"), \n     year(col(\"input\")).alias(\"year\"), \n     month(col(\"input\")).alias(\"month\"), \n     next_day(col(\"input\"),\"Sunday\").alias(\"next_day\"), \n     weekofyear(col(\"input\")).alias(\"weekofyear\") \n  ).show()\n\ndf.select(col(\"input\"),  \n     dayofweek(col(\"input\")).alias(\"dayofweek\"), \n     dayofmonth(col(\"input\")).alias(\"dayofmonth\"), \n     dayofyear(col(\"input\")).alias(\"dayofyear\"), \n  ).show()\n\ndata=[[\"1\",\"02-01-2020 11 01 19 06\"],[\"2\",\"03-01-2019 12 01 19 406\"],[\"3\",\"03-01-2021 12 01 19 406\"]]\ndf2=spark.createDataFrame(data,[\"id\",\"input\"])\ndf2.show(truncate=False)\n\n#current_timestamp()\ndf2.select(current_timestamp().alias(\"current_timestamp\")\n  ).show(1,truncate=False)\n\n#to_timestamp()\ndf2.select(col(\"input\"), \n    to_timestamp(col(\"input\"), \"MM-dd-yyyy HH mm ss SSS\").alias(\"to_timestamp\") \n  ).show(truncate=False)\n\n\n#hour, minute,second\ndata=[[\"1\",\"2020-02-01 11:01:19.06\"],[\"2\",\"2019-03-01 12:01:19.406\"],[\"3\",\"2021-03-01 12:01:19.406\"]]\ndf3=spark.createDataFrame(data,[\"id\",\"input\"])\n\ndf3.select(col(\"input\"), \n    hour(col(\"input\")).alias(\"hour\"), \n    minute(col(\"input\")).alias(\"minute\"),\n    second(col(\"input\")).alias(\"second\") \n  ).show(truncate=False)\n\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f0d1158-6800-4c4c-af42-75198fe0a7b0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"datesDiff\", datediff(current_date(),col(\"input\"))) \\\n  .withColumn(\"montsDiff\", months_between(current_date(),col(\"input\"))) \\\n  .withColumn(\"montsDiff_round\",round(months_between(current_date(),col(\"input\")),2)) \\\n  .withColumn(\"yearsDiff\",months_between(current_date(),col(\"input\"))/lit(12)) \\\n  .withColumn(\"yearsDiff_round\",round(months_between(current_date(),col(\"input\"))/lit(12),2)) \\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e6b09cdb-3082-482c-a497-d24cdb224092","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+----------+---------+-----------+---------------+-----------------+---------------+\n| id|     input|datesDiff|  montsDiff|montsDiff_round|        yearsDiff|yearsDiff_round|\n+---+----------+---------+-----------+---------------+-----------------+---------------+\n|  1|2020-02-01|     1229|40.41935484|          40.42|       3.36827957|           3.37|\n|  2|2019-03-01|     1566|51.41935484|          51.42|4.284946236666666|           4.28|\n|  3|2021-03-01|      835|27.41935484|          27.42|2.284946236666667|           2.28|\n+---+----------+---------+-----------+---------------+-----------------+---------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"select round(months_between('2019-07-01',current_date())/12,2) as years_diff\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d02b9783-db9b-4a37-b12c-1a767e3e1ed1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+\n|years_diff|\n+----------+\n|     -3.95|\n+----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"datesDiff\", datediff(current_date(),col(\"date\"))) \\\n  .withColumn(\"montsDiff\", months_between(current_date(),col(\"date\"))) \\\n  .withColumn(\"montsDiff_round\",round(months_between(current_date(),col(\"date\")),2)) \\\n  .withColumn(\"yearsDiff\",months_between(current_date(),col(\"date\"))/lit(12)) \\\n  .withColumn(\"yearsDiff_round\",round(months_between(current_date(),col(\"date\"))/lit(12),2)) \\\n  .show()\n\ndata2 = [(\"1\",\"07-01-2019\"),(\"2\",\"06-24-2019\"),(\"3\",\"08-24-2019\")]  \ndf2=spark.createDataFrame(data=data2,schema=[\"id\",\"date\"])\ndf2.select(\n    to_date(col(\"date\"),\"MM-dd-yyyy\").alias(\"date\"),\n    current_date().alias(\"endDate\")\n    )\n\n#SQL\n\nspark.sql(\"select round(months_between('2019-07-01',current_date())/12,2) as years_diff\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"67fc92e4-7655-4d69-8e52-578dec0e075b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"date functions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
