{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n\ndept = [(\"Finance\",10), \n        (\"Marketing\",20), \n        (\"Sales\",30), \n        (\"IT\",40) \n      ]\nrdd = spark.sparkContext.parallelize(dept)\n\ndf = rdd.toDF()\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"19a24f9f-4d84-4f83-8e16-bbc17ea92cd5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- _1: string (nullable = true)\n |-- _2: long (nullable = true)\n\n+---------+---+\n|_1       |_2 |\n+---------+---+\n|Finance  |10 |\n|Marketing|20 |\n|Sales    |30 |\n|IT       |40 |\n+---------+---+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["\ndeptColumns = [\"dept_name\",\"dept_id\"]\ndf2 = rdd.toDF(deptColumns)\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4734a423-47d1-4651-86fc-bea95cd51ede","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\ndeptDF.printSchema()\ndeptDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"787e2743-6be1-4cfd-a1fa-fe3900c66ced","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- dept_name: string (nullable = true)\n |-- dept_id: long (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType,StructField, StringType\ndeptSchema = StructType([       \n    StructField('dept_name', StringType(), True),\n    StructField('dept_id', StringType(), True)\n])\n\ndeptDF1 = spark.createDataFrame(data=dept, schema = deptSchema)\ndeptDF1.printSchema()\ndeptDF1.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f1260e00-07c6-4bc8-93d2-aaed449763a9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- dept_name: string (nullable = true)\n |-- dept_id: string (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2299bb40-508e-440f-9cd1-11c4c0ae9166","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"rdd to dataframe","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
