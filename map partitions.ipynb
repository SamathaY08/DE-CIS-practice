{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\ndata = [('James','Smith','M',3000),\n  ('Anna','Rose','F',4100),\n  ('Robert','Williams','M',6200), \n]\n\ncolumns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\ndf = spark.createDataFrame(data=data, schema = columns)\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e2c80071-205e-44eb-b15b-9458f8e1b372","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+--------+------+------+\n|firstname|lastname|gender|salary|\n+---------+--------+------+------+\n|    James|   Smith|     M|  3000|\n|     Anna|    Rose|     F|  4100|\n|   Robert|Williams|     M|  6200|\n+---------+--------+------+------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Example 1 mapPartitions()\ndef reformat(partitionData):\n    for row in partitionData:\n        yield [row.firstname+\",\"+row.lastname,row.salary*10/100]\ndf.rdd.mapPartitions(reformat).toDF().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4974b716-7aaf-4938-acaa-b29707ce174f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------------+-----+\n|             _1|   _2|\n+---------------+-----+\n|    James,Smith|300.0|\n|      Anna,Rose|410.0|\n|Robert,Williams|620.0|\n+---------------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["#Example 2 mapPartitions()\ndef reformat2(partitionData):\n  updatedData = []\n  for row in partitionData:\n    name=row.firstname+\",\"+row.lastname\n    bonus=row.salary*10/100\n    updatedData.append([name,bonus])\n  return iter(updatedData)\n\ndf2=df.rdd.mapPartitions(reformat).toDF([\"name\",\"bonus\"])\ndf2.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"39db71a9-ad51-4cbe-aa43-15dd508bb791","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------------+-----+\n|           name|bonus|\n+---------------+-----+\n|    James,Smith|300.0|\n|      Anna,Rose|410.0|\n|Robert,Williams|620.0|\n+---------------+-----+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa47b1b1-bb27-4ca6-94fa-e5d131a85917","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"map partitions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
