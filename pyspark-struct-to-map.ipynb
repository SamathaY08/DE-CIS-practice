{"cells":[{"cell_type":"code","source":["\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b6409fa8-af2f-499f-90f6-5a828945569d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\ndata = [ (\"36636\",\"Finance\",(3000,\"USA\")), \n    (\"40288\",\"Finance\",(5000,\"IND\")), \n    (\"42114\",\"Sales\",(3900,\"USA\")), \n    (\"39192\",\"Marketing\",(2500,\"CAN\")), \n    (\"34534\",\"Sales\",(6500,\"USA\")) ]\nschema = StructType([\n     StructField('id', StringType(), True),\n     StructField('dept', StringType(), True),\n     StructField('properties', StructType([\n         StructField('salary', IntegerType(), True),\n         StructField('location', StringType(), True)\n         ]))\n     ])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"14d3675a-81f5-4b71-ae35-a79ac9333624","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame(data=data,schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a6759a02-34da-4b5b-811a-7ff70435b7b9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- properties: struct (nullable = true)\n |    |-- salary: integer (nullable = true)\n |    |-- location: string (nullable = true)\n\n+-----+---------+-----------+\n|id   |dept     |properties |\n+-----+---------+-----------+\n|36636|Finance  |{3000, USA}|\n|40288|Finance  |{5000, IND}|\n|42114|Sales    |{3900, USA}|\n|39192|Marketing|{2500, CAN}|\n|34534|Sales    |{6500, USA}|\n+-----+---------+-----------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col,lit,create_map\ndf = df.withColumn(\"propertiesMap\",create_map(\n        lit(\"salary\"),col(\"properties.salary\"),\n        lit(\"location\"),col(\"properties.location\")\n        )).drop(\"properties\")\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"000576ae-5704-4f02-8fa2-29552f68b6c0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- id: string (nullable = true)\n |-- dept: string (nullable = true)\n |-- propertiesMap: map (nullable = false)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+-----+---------+---------------------------------+\n|id   |dept     |propertiesMap                    |\n+-----+---------+---------------------------------+\n|36636|Finance  |{salary -> 3000, location -> USA}|\n|40288|Finance  |{salary -> 5000, location -> IND}|\n|42114|Sales    |{salary -> 3900, location -> USA}|\n|39192|Marketing|{salary -> 2500, location -> CAN}|\n|34534|Sales    |{salary -> 6500, location -> USA}|\n+-----+---------+---------------------------------+\n\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-struct-to-map","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
